Setup a Zookeeper ensemble (cluster of zookeeper with atleast 3 zk peers)
----------------------------------
#Setup atleast 3 machines (ubuntu /centos) within VMbox
centos(c1,c2,c3) as in lab case

Centos Nodes:
Now on each machine
--- to login as root
$sudo su 

---update and install necessary packages
$yum update -y
$yum install vim -y
$yum install wget -y
$yum install openssh-server -y
$yum update -y

---disable firewall
$systemctl status firewalld
$systemctl stop firewalld
$systemctl disable firewalld

---get your ipaddress
$ip address 

---get your hostname
$hostname 

update your /etc/hosts
127.0.0.1     localhost
ipaddress1     hostname1
ipaddress2    hostname2
ipaddress3    hostname3

update hostnames/check hostnames
cat /etc/hostname

sudo visudo and add 'hdu' as user next to root where you see ALL
This will give your user sudo access

$java -version
#if java installed,update java to be able to use JPS command

$yum install java-1.8.0-openjdk-devel

update your java path in your user's .bashrc
(ex: my user hdu)
su - hdu

vi .bashrc
export JAVA_HOME=/usr/lib/jvm/jdk****
export PATH=$PATH:$JAVA_HOME/bin

save your .bashrc
refresh it by ---> source .bashrc

$java -version ( does it show your java version)

Now Generate ssh keys for your user on ubuntu

Commands:
--------------
---Note** we are logged in as 'hdu'
To have SSH access across machines
1.generate ssh keys using 
$ssh-keygen -t rsa -P ""

2.Distributing ssh public keys to other machines
----------------------
$hdu$c1:ssh-copy-id -i $HOME/.ssh/id_rsa.pub hdu@c2
$hdu$c1:ssh-copy-id -i $HOME/.ssh/id_rsa.pub hdu@c3
$hdu$c2:ssh-copy-id -i $HOME/.ssh/id_rsa.pub hdu@c1
$hdu$c2:ssh-copy-id -i $HOME/.ssh/id_rsa.pub hdu@c3
$hdu$c3:ssh-copy-id -i $HOME/.ssh/id_rsa.pub hdu@c1
$hdu$c3:ssh-copy-id -i $HOME/.ssh/id_rsa.pub hdu@c2

3.To enable SSH access to your local machine with this newly created key
----------------------------------------
to add the xxxx@master’s public SSH key (which should be in $HOME/.ssh/id_rsa.pub) 
to the authorized_keys file of xxxx@master(in this user’s $HOME/.ssh/authorized_keys)
c1$cat $HOME/.ssh/id_rsa.pub >> $HOME/.ssh/authorized_keys
c2$cat $HOME/.ssh/id_rsa.pub >> $HOME/.ssh/authorized_keys
c3$cat $HOME/.ssh/id_rsa.pub >> $HOME/.ssh/authorized_keys

Test your ssh access...

#Setup Zk ensemble
---Download zookeeper package from http://archive.apache.org/dist/
zookeeper-3.4.6.tar.gz  

---Download on each node 
   or download on 1st node and then copy(scp) to each node 
   [hdu$c1>scp /home/hdu/Downloads/zookeeper-3.4.6.tar.gz hdu@c2:/home/hdu/Downloads/]
   [hdu$c1>scp /home/hdu/Downloads/zookeeper-3.4.6.tar.gz hdu@c3:/home/hdu/Downloads/]

#check in nodes in /usr/local if it already has zookeeper related directory
$cd /usr/local
$ls -all

#if not..

---After downloading repeat these steps on each node (say c1,c2,c3)

su - root
$cd /usr/local
$tar -xvf /home/hdu/Downloads/zookeeper-3.4.6.tar.gz
$ln -s zookeeper-3.4.6 zookeeper
$chown -R hdu:hdu zookeeper*

$su - hdu
#check if .bashrc has paths for java/zookeeper/kafka set, if already set in one machine, scp .bashrc to other machines
hdu$c1>scp .bashrc hdu@c2:/home/hdu
hdu$c2>scp .bashrc hdu@c3:/home/hdu

#if not then update..
$vi .bashrc
export ZOOKEEPER_HOME=/usr/local/zookeeper
export PATH=$PATH:$ZOOKEEPER_HOME/bin
--save

$source .bashrc

---updating zookeeper configs
$cd /usr/local/zookeeper/conf
$cp zoo_sample.cfg zoo.cfg

--explaination

[tickTime: in milliseconds unit of times for initLimit
 initLimit:zookeeper uses these unit of times to connect to the cluster
 syncLimit: time to come back in sync or peer will out of cluster
  dataDir: cluster related and clients connected to zk cluster data
  clientPort: how clients connect to zk
  maxClientCnxns: how many cleints can connect
  4lw.commands.whitelist=* : enabling 4 letter words such as stat,dump
  2888: port for peers to communicate
  3888: for leader election
]

$vi zoo.cfg

	tickTime=2000
	dataDir=/usr/local/zookeeper/state
	clientPort=2181
	initLimit=5
	syncLimit=2
	server.1=c1:2888:3888
	server.2=c2:2888:3888
	server.3=c3:2888:3888

---we specified the servername as 'hostname' with quorum & leader election ports (i.e. 2888:3888, 2888:3888, 2888:3888) 
---port 2888 for quorum peers to communicate to each other
---port 3888 for leader election

#remember to copy zoo.cfg to /usr/local/zookeeper/conf/ in each machine or edit manually
#note you are in /usr/local/zookeeper/conf

hdu$c1>scp zoo.cfg hdu$c2:/usr/local/zookeeper/conf/
hdu$c1>scp zoo.cfg hdu$c3:/usr/local/zookeeper/conf/

#on each node..
$cd /usr/local/zookeeper
mkdir state

---Every machine that is part of the ZooKeeper ensemble needs to know about every other machine in the ensemble. 
As such, we need to attribute a server id to each machine by creating a file named myid, one for each server,
 which resides in that server's data directory, as specified by the configuration file parameter dataDir.

---Note: More information about ZooKeper configuration settings can be found in the ZooKeeper Getting Started Guide.

#on node1
echo 1 > state/myid
#on node2
echo 2 > state/myid
#on node3
echo 3 > state/myid

ZooKeeper Startup
Start up each ZooKeeper on each host

c1$zkServer.sh start
c2$zkServer.sh start
c3$zkServer.sh start

#check status of which peer acts as leader/follower
$echo stat | nc c1 2181
$echo stat | nc c2 2181
$echo stat | nc c3 2181

#We can also start zookeepers in foreground as follows
c1$zkServer.sh start-foreground
c2$zkServer.sh start-foreground
c3$zkServer.sh start-foreground




